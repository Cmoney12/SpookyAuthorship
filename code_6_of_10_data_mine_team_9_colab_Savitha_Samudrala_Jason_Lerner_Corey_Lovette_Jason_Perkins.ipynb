{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65cc208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/22 22:16:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/22 22:16:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+------+\n",
      "|     id|                text|author|\n",
      "+-------+--------------------+------+\n",
      "|id26305|This process, how...|   EAP|\n",
      "|id17569|It never once occ...|   HPL|\n",
      "|id11008|In his left hand ...|   EAP|\n",
      "|id27763|How lovely is spr...|   MWS|\n",
      "|id12958|Finding nothing e...|   HPL|\n",
      "+-------+--------------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql.functions import length, avg\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "# Start Spark session\n",
    "#spark = SparkSession.builder.appName(\"SpookyAuthor\").getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpookyAuthor\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Load CSV into Spark DataFrame\n",
    "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# View schema\n",
    "df.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1634e2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1634e2f",
    "outputId": "4f0c1c83-fac4-4092-a9aa-fcb9344603c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train\n",
      "+-------+--------------------+------+\n",
      "|     id|                text|author|\n",
      "+-------+--------------------+------+\n",
      "|id26305|This process, how...|   EAP|\n",
      "|id17569|It never once occ...|   HPL|\n",
      "|id11008|In his left hand ...|   EAP|\n",
      "|id27763|How lovely is spr...|   MWS|\n",
      "|id12958|Finding nothing e...|   HPL|\n",
      "|id22965|A youth passed in...|   MWS|\n",
      "|id09674|The astronomer, p...|   EAP|\n",
      "|id13515|The surcingle hun...|   EAP|\n",
      "|id19322|I knew that you c...|   EAP|\n",
      "|id00912|I confess that ne...|   MWS|\n",
      "|id16737|\"He shall find th...|   MWS|\n",
      "|id16607|Here we barricade...|   EAP|\n",
      "|id19764|Herbert West need...|   HPL|\n",
      "|id18886|The farm like gro...|   HPL|\n",
      "|id17189|But a glance will...|   EAP|\n",
      "|id12799|He had escaped me...|   MWS|\n",
      "|id08441|To these speeches...|   EAP|\n",
      "|id13117|Her native sprigh...|   MWS|\n",
      "|id14862|I even went so fa...|   EAP|\n",
      "|id20836|His facial aspect...|   HPL|\n",
      "+-------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test\n",
      "+-------+--------------------+\n",
      "|     id|                text|\n",
      "+-------+--------------------+\n",
      "|id02310|Still, as I urged...|\n",
      "|id24541|If a fire wanted ...|\n",
      "|id00134|And when they had...|\n",
      "|id27757|While I was think...|\n",
      "|id04081|I am not sure to ...|\n",
      "|id27337|\"\"\"The thick and ...|\n",
      "|id24265|That which is not...|\n",
      "|id25917|I sought for repo...|\n",
      "|id04951|Upon the fourth d...|\n",
      "|id14549|\"\"\"The tone metap...|\n",
      "|id22505|These, the offspr...|\n",
      "|id24002|\"What kept him fr...|\n",
      "|id18982|\"Persuading the w...|\n",
      "|id15181|When I arose trem...|\n",
      "|id21888|And by the shores...|\n",
      "|id12035|Idris heard of he...|\n",
      "|id17991|I say this proudl...|\n",
      "|id10707|\"But let us glanc...|\n",
      "|id07101|\"\"\"What a place i...|\n",
      "|id00345|At his nod I took...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_train = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "print(\"\\nTrain\")\n",
    "df_train.show()\n",
    "\n",
    "df_test = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
    "print(\"\\nTest\")\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236f963d-bc74-42e7-b4ef-f397c807a48b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "236f963d-bc74-42e7-b4ef-f397c807a48b",
    "outputId": "a5054d58-a707-4cb9-b39f-0806a3cef4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|text|author|\n",
      "+---+----+------+\n",
      "|  0|   0|     0|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# Get list of numeric columns\n",
    "numeric_types = [\"DoubleType\", \"IntegerType\", \"FloatType\", \"LongType\"]\n",
    "numeric_columns = [f.name for f in df_train.schema.fields if f.dataType.simpleString() in [t.lower().replace(\"type\", \"\") for t in numeric_types]]\n",
    "\n",
    "# Apply isnan() only to numeric columns, isNull() to all\n",
    "df_train.select([\n",
    "    count(\n",
    "        when(\n",
    "            col(c).isNull() | (isnan(col(c)) if c in numeric_columns else False),\n",
    "            c\n",
    "        )\n",
    "    ).alias(c)\n",
    "    for c in df_train.columns\n",
    "]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tetZwc9UwqwW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tetZwc9UwqwW",
    "outputId": "5885be5a-3f58-44c2-bfcc-aee6ac231b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------------------+--------------------+\n",
      "|     id|                text|author|              tokens|     filtered_tokens|\n",
      "+-------+--------------------+------+--------------------+--------------------+\n",
      "|id26305|This process, how...|   EAP|[this, process,, ...|[process,, howeve...|\n",
      "|id17569|It never once occ...|   HPL|[it, never, once,...|[never, occurred,...|\n",
      "|id11008|In his left hand ...|   EAP|[in, his, left, h...|[left, hand, gold...|\n",
      "|id27763|How lovely is spr...|   MWS|[how, lovely, is,...|[lovely, spring, ...|\n",
      "|id12958|Finding nothing e...|   HPL|[finding, nothing...|[finding, nothing...|\n",
      "|id22965|A youth passed in...|   MWS|[a, youth, passed...|[youth, passed, s...|\n",
      "|id09674|The astronomer, p...|   EAP|[the, astronomer,...|[astronomer,, per...|\n",
      "|id13515|The surcingle hun...|   EAP|[the, surcingle, ...|[surcingle, hung,...|\n",
      "|id19322|I knew that you c...|   EAP|[i, knew, that, y...|[knew, say, 'ster...|\n",
      "|id00912|I confess that ne...|   MWS|[i, confess, that...|[confess, neither...|\n",
      "|id16737|\"He shall find th...|   MWS|[\"he, shall, find...|[\"he, shall, find...|\n",
      "|id16607|Here we barricade...|   EAP|[here, we, barric...|[barricaded, ours...|\n",
      "|id19764|Herbert West need...|   HPL|[herbert, west, n...|[herbert, west, n...|\n",
      "|id18886|The farm like gro...|   HPL|[the, farm, like,...|[farm, like, grou...|\n",
      "|id17189|But a glance will...|   EAP|[but, a, glance, ...|[glance, show, fa...|\n",
      "|id12799|He had escaped me...|   MWS|[he, had, escaped...|[escaped, me,, mu...|\n",
      "|id08441|To these speeches...|   EAP|[to, these, speec...|[speeches, gave,,...|\n",
      "|id13117|Her native sprigh...|   MWS|[her, native, spr...|[native, sprightl...|\n",
      "|id14862|I even went so fa...|   EAP|[i, even, went, s...|[even, went, far,...|\n",
      "|id20836|His facial aspect...|   HPL|[his, facial, asp...|[facial, aspect,,...|\n",
      "+-------+--------------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Step 1: Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "df_train_tokenized = tokenizer.transform(df_train)\n",
    "\n",
    "# Step 2: Stop word removal\n",
    "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\") + ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her']\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
    "df_train_filtered = remover.transform(df_train_tokenized)\n",
    "\n",
    "\n",
    "df_train_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vcFk2jgkxLXp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcFk2jgkxLXp",
    "outputId": "dd3b9a8c-4089-40b4-bb91-d5e1c5741f36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     id|                text|author|     filtered_tokens|        raw_features|      tfidf_features| normalized_features|\n",
      "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|id26305|This process, how...|   EAP|[process,, howeve...|(9079,[4,9,33,47,...|(9079,[4,9,33,47,...|(9079,[4,9,33,47,...|\n",
      "|id17569|It never once occ...|   HPL|[never, occurred,...|(9079,[4,10,228,7...|(9079,[4,10,228,7...|(9079,[4,10,228,7...|\n",
      "|id11008|In his left hand ...|   EAP|[left, hand, gold...|(9079,[48,87,136,...|(9079,[48,87,136,...|(9079,[48,87,136,...|\n",
      "|id27763|How lovely is spr...|   MWS|[lovely, spring, ...|(9079,[85,88,422,...|(9079,[85,88,422,...|(9079,[85,88,422,...|\n",
      "|id12958|Finding nothing e...|   HPL|[finding, nothing...|(9079,[2,67,145,3...|(9079,[2,67,145,3...|(9079,[2,67,145,3...|\n",
      "|id22965|A youth passed in...|   MWS|[youth, passed, s...|(9079,[10,41,42,6...|(9079,[10,41,42,6...|(9079,[10,41,42,6...|\n",
      "|id09674|The astronomer, p...|   EAP|[astronomer,, per...|(9079,[59,87,188,...|(9079,[59,87,188,...|(9079,[59,87,188,...|\n",
      "|id13515|The surcingle hun...|   EAP|[surcingle, hung,...|(9079,[504,4119],...|(9079,[504,4119],...|(9079,[504,4119],...|\n",
      "|id19322|I knew that you c...|   EAP|[knew, say, 'ster...|(9079,[3,19,20,21...|(9079,[3,19,20,21...|(9079,[3,19,20,21...|\n",
      "|id00912|I confess that ne...|   MWS|[confess, neither...|(9079,[49,277,357...|(9079,[49,277,357...|(9079,[49,277,357...|\n",
      "|id16737|\"He shall find th...|   MWS|[\"he, shall, find...|(9079,[40,105,149...|(9079,[40,105,149...|(9079,[40,105,149...|\n",
      "|id16607|Here we barricade...|   EAP|[barricaded, ours...|(9079,[36,181,469...|(9079,[36,181,469...|(9079,[36,181,469...|\n",
      "|id19764|Herbert West need...|   HPL|[herbert, west, n...|(9079,[38,283,304...|(9079,[38,283,304...|(9079,[38,283,304...|\n",
      "|id18886|The farm like gro...|   HPL|[farm, like, grou...|(9079,[6,73,81,92...|(9079,[6,73,81,92...|(9079,[6,73,81,92...|\n",
      "|id17189|But a glance will...|   EAP|[glance, show, fa...|(9079,[1009,1597,...|(9079,[1009,1597,...|(9079,[1009,1597,...|\n",
      "|id12799|He had escaped me...|   MWS|[escaped, me,, mu...|(9079,[7,21,22,81...|(9079,[7,21,22,81...|(9079,[7,21,22,81...|\n",
      "|id08441|To these speeches...|   EAP|[speeches, gave,,...|(9079,[20,51,72,8...|(9079,[20,51,72,8...|(9079,[20,51,72,8...|\n",
      "|id13117|Her native sprigh...|   MWS|[native, sprightl...|(9079,[30,88,301,...|(9079,[30,88,301,...|(9079,[30,88,301,...|\n",
      "|id14862|I even went so fa...|   EAP|[even, went, far,...|(9079,[0,2,36,37,...|(9079,[0,2,36,37,...|(9079,[0,2,36,37,...|\n",
      "|id20836|His facial aspect...|   HPL|[facial, aspect,,...|(9079,[30,31,45,8...|(9079,[30,31,45,8...|(9079,[30,31,45,8...|\n",
      "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     id|                text|     filtered_tokens|        raw_features|      tfidf_features| normalized_features|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|id02310|Still, as I urged...|[still,, urged, l...|(9079,[32,159,271...|(9079,[32,159,271...|(9079,[32,159,271...|\n",
      "|id24541|If a fire wanted ...|[fire, wanted, fa...|(9079,[34,168,177...|(9079,[34,168,177...|(9079,[34,168,177...|\n",
      "|id00134|And when they had...|[broken, frail, d...|(9079,[15,26,62,1...|(9079,[15,26,62,1...|(9079,[15,26,62,1...|\n",
      "|id27757|While I was think...|[thinking, possib...|(9079,[0,33,36,19...|(9079,[0,33,36,19...|(9079,[0,33,36,19...|\n",
      "|id04081|I am not sure to ...|[sure, limit, kno...|(9079,[27,343,494...|(9079,[27,343,494...|(9079,[27,343,494...|\n",
      "|id27337|\"\"\"The thick and ...|[\"\"\"the, thick, p...|(9079,[312,457,10...|(9079,[312,457,10...|(9079,[312,457,10...|\n",
      "|id24265|That which is not...|[matter,, unless,...|(9079,[1369,2129,...|(9079,[1369,2129,...|(9079,[1369,2129,...|\n",
      "|id25917|I sought for repo...|[sought, repose, ...|(9079,[0,66,83,18...|(9079,[0,66,83,18...|(9079,[0,66,83,18...|\n",
      "|id04951|Upon the fourth d...|[upon, fourth, da...|(9079,[1,35,65,48...|(9079,[1,35,65,48...|(9079,[1,35,65,48...|\n",
      "|id14549|\"\"\"The tone metap...|[\"\"\"the, tone, me...|(9079,[89,137,457...|(9079,[89,137,457...|(9079,[89,137,457...|\n",
      "|id22505|These, the offspr...|[these,, offsprin...|(9079,[9,168,299,...|(9079,[9,168,299,...|(9079,[9,168,299,...|\n",
      "|id24002|\"What kept him fr...|[\"what, kept, goi...|(9079,[90,187,348...|(9079,[90,187,348...|(9079,[90,187,348...|\n",
      "|id18982|\"Persuading the w...|[\"persuading, wid...|(9079,[562,2869,4...|(9079,[562,2869,4...|(9079,[562,2869,4...|\n",
      "|id15181|When I arose trem...|[arose, trembling...|(9079,[12,24,58,7...|(9079,[12,24,58,7...|(9079,[12,24,58,7...|\n",
      "|id21888|And by the shores...|[shores, river, z...|(9079,[277,531,84...|(9079,[277,531,84...|(9079,[277,531,84...|\n",
      "|id12035|Idris heard of he...|[idris, heard, mo...|(9079,[42,245,565...|(9079,[42,245,565...|(9079,[42,245,565...|\n",
      "|id17991|I say this proudl...|[say, proudly,, t...|(9079,[31,72,380,...|(9079,[31,72,380,...|(9079,[31,72,380,...|\n",
      "|id10707|\"But let us glanc...|[\"but, let, us, g...|(9079,[28,59,1009...|(9079,[28,59,1009...|(9079,[28,59,1009...|\n",
      "|id07101|\"\"\"What a place i...|[\"\"\"what, place, ...|(9079,[78,3539,90...|(9079,[78,3539,90...|(9079,[78,3539,90...|\n",
      "|id00345|At his nod I took...|[nod, took, one, ...|(9079,[0,1,87,239...|(9079,[0,1,87,239...|(9079,[0,1,87,239...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#Stage 2: Feature Extraction\n",
    "\n",
    "#TF-IDF Feature Extraction\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "#convert filtered tokens to term frequency vectors\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"raw_features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "#set IDF to scale term frequencies by inverse document frequency\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
    "\n",
    "#normalize the TF-IDF features\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "#normalize the TF-IDF features using L2 norm (len)\n",
    "normalizer = Normalizer(inputCol=\"tfidf_features\", outputCol=\"normalized_features\", p=2.0)\n",
    "\n",
    "#build and apply pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#create pipeline with existing tokenizer, stop word remover, and new stages\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer,\n",
    "    remover,\n",
    "    count_vectorizer,\n",
    "    idf,\n",
    "    normalizer\n",
    "])\n",
    "\n",
    "#fit pipeline to training data\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "\n",
    "#transform training data\n",
    "df_train_transformed = pipeline_model.transform(df_train)\n",
    "\n",
    "#show transformed training data with added feature columns\n",
    "df_train_transformed.select(\"id\", \"text\", \"author\", \"filtered_tokens\", \"raw_features\", \"tfidf_features\", \"normalized_features\").show()\n",
    "\n",
    "#apply pipeline to the test data\n",
    "df_test_transformed = pipeline_model.transform(df_test)\n",
    "\n",
    "#show transformed test data\n",
    "df_test_transformed.select(\"id\", \"text\", \"filtered_tokens\", \"raw_features\", \"tfidf_features\", \"normalized_features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b165b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data (80% train, 20% validation)\n",
    "train_data, val_data = df_train_transformed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Optional: cache if large\n",
    "# train_data.cache()\n",
    "# val_data.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fabf68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 22:16:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/07/22 22:17:00 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.0.0.177:53889 is closed\n",
      "25/07/22 22:17:00 ERROR ChunkFetchRequestHandler: Error sending result ChunkFetchSuccess[streamChunkId=StreamChunkId[streamId=2030366165001,chunkIndex=0],buffer=org.apache.spark.storage.BlockManagerManagedBuffer@2766657c] to /10.0.0.177:53900; closing connection\n",
      "java.io.IOException: No buffer space available\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:62)\n",
      "\tat java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:132)\n",
      "\tat java.base/sun.nio.ch.IOUtil.write(IOUtil.java:97)\n",
      "\tat java.base/sun.nio.ch.IOUtil.write(IOUtil.java:53)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:532)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferFileRegion.transferTo(ChunkedByteBufferFileRegion.scala:60)\n",
      "\tat org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:122)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:368)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:406)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:929)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:366)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:790)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/07/22 22:17:49 WARN StringIndexerModel: Input column author does not exist during transformation. Skip StringIndexerModel for this column.\n",
      "25/07/22 22:17:50 WARN DAGScheduler: Broadcasting large task binary with size 90.0 MiB\n",
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Build pipeline using training data\n",
    "label_indexer = StringIndexer(inputCol=\"author\", outputCol=\"label\")\n",
    "lr = LogisticRegression(featuresCol=\"normalized_features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=[label_indexer, lr])\n",
    "\n",
    "# ðŸ‘‡ Fit model on the TRAINING DATA only\n",
    "model = pipeline.fit(df_train_transformed)  # or train_data if you split earlier\n",
    "\n",
    "# ðŸ‘‡ Now make predictions on the TEST set (which does NOT have 'author')\n",
    "predictions = model.transform(df_test_transformed)\n",
    "\n",
    "# If you want to evaluate, you must evaluate on validation data that *has* labels:\n",
    "val_predictions = model.transform(val_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(val_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bccfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 22:34:27 WARN DAGScheduler: Broadcasting large task binary with size 90.0 MiB\n",
      "[Stage 325:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate F1 score\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = f1_evaluator.evaluate(val_predictions)\n",
    "print(f\"Validation F1 Score: {f1_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ace43a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top EAP words:\n",
      "               word        EAP        HPL        MWS\n",
      "7973            les  31.529796  -7.115751  -6.693555\n",
      "7673         renown  28.767139  -7.372131  -5.048677\n",
      "8531        garret,  28.705112  -1.941936 -24.790361\n",
      "5967    mountainous  28.670752 -10.619615  -8.572036\n",
      "5955  acquaintance,  27.572957  -6.513499  -5.107116\n",
      "7677          valor  26.903874 -16.308050  -3.191897\n",
      "8481       momently  26.850046  -3.723839 -21.637591\n",
      "8033        slight,  24.678751 -12.905075  -5.766720\n",
      "6071        driving  24.616322 -10.922387  -6.734704\n",
      "6113        darkest  23.946692 -16.765882   2.087710\n",
      "\n",
      "Top HPL words:\n",
      "            word        EAP        HPL        MWS\n",
      "7898     wedding  -6.713819  30.362181  -4.856881\n",
      "5243      close, -20.364282  28.105938  -5.631452\n",
      "7068      defeat -19.671866  28.047485  -1.312548\n",
      "8237    ecstasy, -26.779940  25.973695   2.196979\n",
      "7972       murky  -6.331920  25.301273 -16.558625\n",
      "4699      given,   0.055081  24.961775  -7.473968\n",
      "6679     nature;  -8.133241  24.103306 -13.594922\n",
      "7147       renew -15.979093  24.099040  -3.189441\n",
      "8866  increased; -18.000499  23.686566  -4.055434\n",
      "5283         row   0.072791  23.552586 -13.209891\n",
      "\n",
      "Top MWS words:\n",
      "           word        EAP        HPL        MWS\n",
      "8982     peered -22.996424  -3.800947  27.816340\n",
      "5805      waxed -12.054030 -13.224890  27.718995\n",
      "4711     vistas -18.064022  -6.491359  26.789482\n",
      "3386     waning -18.793478  -7.009358  26.252024\n",
      "4986     cattle -21.424890  -1.909939  25.198653\n",
      "6811  rumblings  -6.692035 -15.815306  24.987429\n",
      "8080   platform -22.428994  -1.772360  24.913428\n",
      "7855      lunch -16.849862  -6.059742  24.870766\n",
      "6954  clearness  -7.250648 -11.508554  24.450224\n",
      "3620      arter -15.217959  -5.247615  24.207527\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Get the trained Logistic Regression model from pipeline\n",
    "lr_model = model.stages[-1]  # last stage\n",
    "vectorizer_model = pipeline_model.stages[2]  # CountVectorizer is stage 2 in your pipeline\n",
    "\n",
    "# Step 2: Get vocabulary\n",
    "vocab = vectorizer_model.vocabulary  # list of words\n",
    "\n",
    "# Step 3: Get coefficients\n",
    "coefs = lr_model.coefficientMatrix.toArray()  # shape: (numClasses, numFeatures)\n",
    "\n",
    "# Step 4: Wrap into DataFrame\n",
    "feature_weights = pd.DataFrame({\n",
    "    \"word\": vocab,\n",
    "    \"EAP\": coefs[0],  # assuming label 0 = EAP\n",
    "    \"HPL\": coefs[1],\n",
    "    \"MWS\": coefs[2],\n",
    "})\n",
    "\n",
    "# Step 5: View top words per class\n",
    "print(\"Top EAP words:\")\n",
    "print(feature_weights.sort_values(\"EAP\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop HPL words:\")\n",
    "print(feature_weights.sort_values(\"HPL\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop MWS words:\")\n",
    "print(feature_weights.sort_values(\"MWS\", ascending=False).head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c800c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We performed a logistic regression with an accuracy of 97.4%.  And the confusion matrix shows strong correlation (high positive values) for key words from an author in their works while the absence of those key words (negative values) in the other author's works.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
