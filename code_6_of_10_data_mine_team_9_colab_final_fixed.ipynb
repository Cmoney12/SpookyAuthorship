{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8eac54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "cd8eac54",
        "outputId": "e3c5b9fc-d304-46f9-86ee-6e87b49ec43c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e4ad45b7fd0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2c4c23b88af5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab Spark App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#install required dependencies\n",
        "!pip install -q pyspark  # Installs PySpark library\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null  # Installs Java 8, required for Spark (Google Colab only, remove if not in Colab)\n",
        "\n",
        "#download and extract Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz  #downloads Spark 3.3.0 (Google Colab only, remove if not in Colab)\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz  #extracts Spark tarball (Google Colab only, remove if not in Colab)\n",
        "\n",
        "#set environment variables for Java and Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"  #sets Java path (Google Colab only, adjust or remove if not in Colab)\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"  #sets Spark path (Google Colab only, adjust or remove if not in Colab)\n",
        "\n",
        "#initialize Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab Spark App\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "#verify Spark session\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1634e2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1634e2f",
        "outputId": "4f0c1c83-fac4-4092-a9aa-fcb9344603c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access files\n",
        "# REMOVE this cell if running outside Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d442ce3-4891-4224-a914-5b4e1938a37d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d442ce3-4891-4224-a914-5b4e1938a37d",
        "outputId": "82f3f8e3-5f80-4739-a272-0132f3b8b04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train\n",
            "+-------+--------------------+------+\n",
            "|     id|                text|author|\n",
            "+-------+--------------------+------+\n",
            "|id26305|This process, how...|   EAP|\n",
            "|id17569|It never once occ...|   HPL|\n",
            "|id11008|In his left hand ...|   EAP|\n",
            "|id27763|How lovely is spr...|   MWS|\n",
            "|id12958|Finding nothing e...|   HPL|\n",
            "|id22965|A youth passed in...|   MWS|\n",
            "|id09674|The astronomer, p...|   EAP|\n",
            "|id13515|The surcingle hun...|   EAP|\n",
            "|id19322|I knew that you c...|   EAP|\n",
            "|id00912|I confess that ne...|   MWS|\n",
            "|id16737|\"He shall find th...|   MWS|\n",
            "|id16607|Here we barricade...|   EAP|\n",
            "|id19764|Herbert West need...|   HPL|\n",
            "|id18886|The farm like gro...|   HPL|\n",
            "|id17189|But a glance will...|   EAP|\n",
            "|id12799|He had escaped me...|   MWS|\n",
            "|id08441|To these speeches...|   EAP|\n",
            "|id13117|Her native sprigh...|   MWS|\n",
            "|id14862|I even went so fa...|   EAP|\n",
            "|id20836|His facial aspect...|   HPL|\n",
            "+-------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Test\n",
            "+-------+--------------------+\n",
            "|     id|                text|\n",
            "+-------+--------------------+\n",
            "|id02310|Still, as I urged...|\n",
            "|id24541|If a fire wanted ...|\n",
            "|id00134|And when they had...|\n",
            "|id27757|While I was think...|\n",
            "|id04081|I am not sure to ...|\n",
            "|id27337|\"\"\"The thick and ...|\n",
            "|id24265|That which is not...|\n",
            "|id25917|I sought for repo...|\n",
            "|id04951|Upon the fourth d...|\n",
            "|id14549|\"\"\"The tone metap...|\n",
            "|id22505|These, the offspr...|\n",
            "|id24002|\"What kept him fr...|\n",
            "|id18982|\"Persuading the w...|\n",
            "|id15181|When I arose trem...|\n",
            "|id21888|And by the shores...|\n",
            "|id12035|Idris heard of he...|\n",
            "|id17991|I say this proudl...|\n",
            "|id10707|\"But let us glanc...|\n",
            "|id07101|\"\"\"What a place i...|\n",
            "|id00345|At his nod I took...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df_train = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
        "df_train = spark.read.csv(\"/content/drive/MyDrive/train.csv\", header=True, inferSchema=True)\n",
        "# Use the above line only in Google Colab with Google Drive mounted.\n",
        "# Remove it and uncomment the original line for local environments.\n",
        "print(\"\\nTrain\")\n",
        "df_train.show()\n",
        "\n",
        "# df_test = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
        "df_test = spark.read.csv(\"/content/drive/MyDrive/test.csv\", header=True, inferSchema=True)\n",
        "# Use the above line only in Google Colab with Google Drive mounted.\n",
        "# Remove it and uncomment the original line for local environments.\n",
        "print(\"\\nTest\")\n",
        "df_test.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236f963d-bc74-42e7-b4ef-f397c807a48b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "236f963d-bc74-42e7-b4ef-f397c807a48b",
        "outputId": "a5054d58-a707-4cb9-b39f-0806a3cef4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+------+\n",
            "| id|text|author|\n",
            "+---+----+------+\n",
            "|  0|   0|     0|\n",
            "+---+----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check for null\n",
        "from pyspark.sql.functions import col, isnan, when, count\n",
        "\n",
        "df_train.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df_train.columns]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tetZwc9UwqwW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tetZwc9UwqwW",
        "outputId": "5885be5a-3f58-44c2-bfcc-aee6ac231b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "|     id|                text|author|              tokens|     filtered_tokens|\n",
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "|id26305|This process, how...|   EAP|[this, process,, ...|[process,, howeve...|\n",
            "|id17569|It never once occ...|   HPL|[it, never, once,...|[never, occurred,...|\n",
            "|id11008|In his left hand ...|   EAP|[in, his, left, h...|[left, hand, gold...|\n",
            "|id27763|How lovely is spr...|   MWS|[how, lovely, is,...|[lovely, spring, ...|\n",
            "|id12958|Finding nothing e...|   HPL|[finding, nothing...|[finding, nothing...|\n",
            "|id22965|A youth passed in...|   MWS|[a, youth, passed...|[youth, passed, s...|\n",
            "|id09674|The astronomer, p...|   EAP|[the, astronomer,...|[astronomer,, per...|\n",
            "|id13515|The surcingle hun...|   EAP|[the, surcingle, ...|[surcingle, hung,...|\n",
            "|id19322|I knew that you c...|   EAP|[i, knew, that, y...|[knew, say, 'ster...|\n",
            "|id00912|I confess that ne...|   MWS|[i, confess, that...|[confess, neither...|\n",
            "|id16737|\"He shall find th...|   MWS|[\"he, shall, find...|[\"he, shall, find...|\n",
            "|id16607|Here we barricade...|   EAP|[here, we, barric...|[barricaded, ours...|\n",
            "|id19764|Herbert West need...|   HPL|[herbert, west, n...|[herbert, west, n...|\n",
            "|id18886|The farm like gro...|   HPL|[the, farm, like,...|[farm, like, grou...|\n",
            "|id17189|But a glance will...|   EAP|[but, a, glance, ...|[glance, show, fa...|\n",
            "|id12799|He had escaped me...|   MWS|[he, had, escaped...|[escaped, me,, mu...|\n",
            "|id08441|To these speeches...|   EAP|[to, these, speec...|[speeches, gave,,...|\n",
            "|id13117|Her native sprigh...|   MWS|[her, native, spr...|[native, sprightl...|\n",
            "|id14862|I even went so fa...|   EAP|[i, even, went, s...|[even, went, far,...|\n",
            "|id20836|His facial aspect...|   HPL|[his, facial, asp...|[facial, aspect,,...|\n",
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover, Tokenizer\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Step 1: Tokenization\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
        "df_train_tokenized = tokenizer.transform(df_train)\n",
        "\n",
        "# Step 2: Stop word removal\n",
        "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\") + ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her']\n",
        "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
        "df_train_filtered = remover.transform(df_train_tokenized)\n",
        "\n",
        "\n",
        "df_train_filtered.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vcFk2jgkxLXp",
      "metadata": {
        "id": "vcFk2jgkxLXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3b9a8c-4089-40b4-bb91-d5e1c5741f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     id|                text|author|     filtered_tokens|        raw_features|      tfidf_features| normalized_features|\n",
            "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
            "|id26305|This process, how...|   EAP|[process,, howeve...|(9079,[4,9,33,47,...|(9079,[4,9,33,47,...|(9079,[4,9,33,47,...|\n",
            "|id17569|It never once occ...|   HPL|[never, occurred,...|(9079,[4,10,231,7...|(9079,[4,10,231,7...|(9079,[4,10,231,7...|\n",
            "|id11008|In his left hand ...|   EAP|[left, hand, gold...|(9079,[48,87,135,...|(9079,[48,87,135,...|(9079,[48,87,135,...|\n",
            "|id27763|How lovely is spr...|   MWS|[lovely, spring, ...|(9079,[85,88,420,...|(9079,[85,88,420,...|(9079,[85,88,420,...|\n",
            "|id12958|Finding nothing e...|   HPL|[finding, nothing...|(9079,[2,67,143,3...|(9079,[2,67,143,3...|(9079,[2,67,143,3...|\n",
            "|id22965|A youth passed in...|   MWS|[youth, passed, s...|(9079,[10,41,42,6...|(9079,[10,41,42,6...|(9079,[10,41,42,6...|\n",
            "|id09674|The astronomer, p...|   EAP|[astronomer,, per...|(9079,[59,87,190,...|(9079,[59,87,190,...|(9079,[59,87,190,...|\n",
            "|id13515|The surcingle hun...|   EAP|[surcingle, hung,...|(9079,[505,4169],...|(9079,[505,4169],...|(9079,[505,4169],...|\n",
            "|id19322|I knew that you c...|   EAP|[knew, say, 'ster...|(9079,[3,19,20,21...|(9079,[3,19,20,21...|(9079,[3,19,20,21...|\n",
            "|id00912|I confess that ne...|   MWS|[confess, neither...|(9079,[49,277,367...|(9079,[49,277,367...|(9079,[49,277,367...|\n",
            "|id16737|\"He shall find th...|   MWS|[\"he, shall, find...|(9079,[40,105,147...|(9079,[40,105,147...|(9079,[40,105,147...|\n",
            "|id16607|Here we barricade...|   EAP|[barricaded, ours...|(9079,[36,181,471...|(9079,[36,181,471...|(9079,[36,181,471...|\n",
            "|id19764|Herbert West need...|   HPL|[herbert, west, n...|(9079,[38,282,306...|(9079,[38,282,306...|(9079,[38,282,306...|\n",
            "|id18886|The farm like gro...|   HPL|[farm, like, grou...|(9079,[6,71,79,92...|(9079,[6,71,79,92...|(9079,[6,71,79,92...|\n",
            "|id17189|But a glance will...|   EAP|[glance, show, fa...|(9079,[1006,1594,...|(9079,[1006,1594,...|(9079,[1006,1594,...|\n",
            "|id12799|He had escaped me...|   MWS|[escaped, me,, mu...|(9079,[7,21,22,79...|(9079,[7,21,22,79...|(9079,[7,21,22,79...|\n",
            "|id08441|To these speeches...|   EAP|[speeches, gave,,...|(9079,[20,51,73,8...|(9079,[20,51,73,8...|(9079,[20,51,73,8...|\n",
            "|id13117|Her native sprigh...|   MWS|[native, sprightl...|(9079,[30,88,298,...|(9079,[30,88,298,...|(9079,[30,88,298,...|\n",
            "|id14862|I even went so fa...|   EAP|[even, went, far,...|(9079,[0,2,36,37,...|(9079,[0,2,36,37,...|(9079,[0,2,36,37,...|\n",
            "|id20836|His facial aspect...|   HPL|[facial, aspect,,...|(9079,[30,31,45,7...|(9079,[30,31,45,7...|(9079,[30,31,45,7...|\n",
            "+-------+--------------------+------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     id|                text|     filtered_tokens|        raw_features|      tfidf_features| normalized_features|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|id02310|Still, as I urged...|[still,, urged, l...|(9079,[32,159,270...|(9079,[32,159,270...|(9079,[32,159,270...|\n",
            "|id24541|If a fire wanted ...|[fire, wanted, fa...|(9079,[34,168,179...|(9079,[34,168,179...|(9079,[34,168,179...|\n",
            "|id00134|And when they had...|[broken, frail, d...|(9079,[15,26,62,1...|(9079,[15,26,62,1...|(9079,[15,26,62,1...|\n",
            "|id27757|While I was think...|[thinking, possib...|(9079,[0,33,36,19...|(9079,[0,33,36,19...|(9079,[0,33,36,19...|\n",
            "|id04081|I am not sure to ...|[sure, limit, kno...|(9079,[27,343,490...|(9079,[27,343,490...|(9079,[27,343,490...|\n",
            "|id27337|\"\"\"The thick and ...|[\"\"\"the, thick, p...|(9079,[313,453,10...|(9079,[313,453,10...|(9079,[313,453,10...|\n",
            "|id24265|That which is not...|[matter,, unless,...|(9079,[1364,2133,...|(9079,[1364,2133,...|(9079,[1364,2133,...|\n",
            "|id25917|I sought for repo...|[sought, repose, ...|(9079,[0,66,83,18...|(9079,[0,66,83,18...|(9079,[0,66,83,18...|\n",
            "|id04951|Upon the fourth d...|[upon, fourth, da...|(9079,[1,35,65,49...|(9079,[1,35,65,49...|(9079,[1,35,65,49...|\n",
            "|id14549|\"\"\"The tone metap...|[\"\"\"the, tone, me...|(9079,[89,136,453...|(9079,[89,136,453...|(9079,[89,136,453...|\n",
            "|id22505|These, the offspr...|[these,, offsprin...|(9079,[9,168,299,...|(9079,[9,168,299,...|(9079,[9,168,299,...|\n",
            "|id24002|\"What kept him fr...|[\"what, kept, goi...|(9079,[90,187,354...|(9079,[90,187,354...|(9079,[90,187,354...|\n",
            "|id18982|\"Persuading the w...|[\"persuading, wid...|(9079,[560,2921,4...|(9079,[560,2921,4...|(9079,[560,2921,4...|\n",
            "|id15181|When I arose trem...|[arose, trembling...|(9079,[12,24,58,7...|(9079,[12,24,58,7...|(9079,[12,24,58,7...|\n",
            "|id21888|And by the shores...|[shores, river, z...|(9079,[277,532,84...|(9079,[277,532,84...|(9079,[277,532,84...|\n",
            "|id12035|Idris heard of he...|[idris, heard, mo...|(9079,[42,247,574...|(9079,[42,247,574...|(9079,[42,247,574...|\n",
            "|id17991|I say this proudl...|[say, proudly,, t...|(9079,[31,73,378,...|(9079,[31,73,378,...|(9079,[31,73,378,...|\n",
            "|id10707|\"But let us glanc...|[\"but, let, us, g...|(9079,[28,59,1006...|(9079,[28,59,1006...|(9079,[28,59,1006...|\n",
            "|id07101|\"\"\"What a place i...|[\"\"\"what, place, ...|(9079,[78,3371,90...|(9079,[78,3371,90...|(9079,[78,3371,90...|\n",
            "|id00345|At his nod I took...|[nod, took, one, ...|(9079,[0,1,87,237...|(9079,[0,1,87,237...|(9079,[0,1,87,237...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Stage 2: Feature Extraction\n",
        "\n",
        "#TF-IDF Feature Extraction\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "\n",
        "#convert filtered tokens to term frequency vectors\n",
        "count_vectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"raw_features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "#set IDF to scale term frequencies by inverse document frequency\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
        "\n",
        "#normalize the TF-IDF features\n",
        "from pyspark.ml.feature import Normalizer\n",
        "\n",
        "#normalize the TF-IDF features using L2 norm (len)\n",
        "normalizer = Normalizer(inputCol=\"tfidf_features\", outputCol=\"normalized_features\", p=2.0)\n",
        "\n",
        "#build and apply pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "#create pipeline with existing tokenizer, stop word remover, and new stages\n",
        "pipeline = Pipeline(stages=[\n",
        "    tokenizer,\n",
        "    remover,\n",
        "    count_vectorizer,\n",
        "    idf,\n",
        "    normalizer\n",
        "])\n",
        "\n",
        "#fit pipeline to training data\n",
        "pipeline_model = pipeline.fit(df_train)\n",
        "\n",
        "#transform training data\n",
        "df_train_transformed = pipeline_model.transform(df_train)\n",
        "\n",
        "#show transformed training data with added feature columns\n",
        "df_train_transformed.select(\"id\", \"text\", \"author\", \"filtered_tokens\", \"raw_features\", \"tfidf_features\", \"normalized_features\").show()\n",
        "\n",
        "#apply pipeline to the test data\n",
        "df_test_transformed = pipeline_model.transform(df_test)\n",
        "\n",
        "#show transformed test data\n",
        "df_test_transformed.select(\"id\", \"text\", \"filtered_tokens\", \"raw_features\", \"tfidf_features\", \"normalized_features\").show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}